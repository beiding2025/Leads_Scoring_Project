{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOUzqcG0qW8An5iI/ApwnJn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Google Map API\n","!pip install googlemaps"],"metadata":{"id":"hkT218g3jsRO"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZLO8cMjljg6l"},"outputs":[],"source":["import pandas as pd\n","import re\n","import requests\n","from difflib import SequenceMatcher\n","from fuzzywuzzy import fuzz\n","\n","CONFIG = {\n","    'input_file': 'Leads.csv',\n","    'output_file': 'LEADS_with_PlacesAPI_WeightedScore.csv',\n","    'api_key': 'API Key',\n","    'target_cuisines': ['restaurant', 'bar', 'cafe', 'shop', 'bakery', 'breakfast', 'deli', 'catering', 'food', 'meal', 'diner'],\n","    'matching_threshold': 0.65,\n","    'column_mapping': {\n","        'restaurant_name': 'restaurant_name',\n","        'address': 'address',\n","        'address_line_2': 'address_line_2',\n","        'city': 'city',\n","        'state': 'state',\n","        'postal_code': 'postal_code',\n","        'county': 'county',\n","        'country': 'country'\n","    },\n","    'weights': {\n","        'status': 0.30,\n","        'cuisine_match': 0.10,\n","        'address_match': 0.30,\n","        'name_match': 0.20,\n","        'website': 0.10\n","    }\n","}\n","\n","def clean_text(value):\n","    if isinstance(value, str):\n","        return value.replace(\"&#x27;\", \"`\").replace(\"&amp;\", \"&\").replace(\"&#x2F;\", \"/\")\n","    return value\n","\n","def normalize_postal_code(postal_code):\n","    postal_code = str(postal_code).strip().split('-')[0]\n","    return postal_code.zfill(5)[:5]\n","\n","def refine_address_with_unit(address):\n","    if pd.isna(address):\n","        return \"\"\n","    address = address.lower().strip()\n","    address = re.sub(r'\\b(suite|unit|apt|apartment|floor|ste|#)\\s*\\d+[a-zA-Z]*', '', address)\n","    address = re.sub(r'#\\d+[a-zA-Z]*', '', address)\n","    address = re.sub(r'\\s*,\\s*', ', ', address)\n","    address = re.sub(r',+', ',', address)\n","    address = re.sub(r'\\s+', ' ', address)\n","    return address.strip(', ')\n","\n","def normalize_address(address):\n","    if pd.isna(address):\n","        return \"\"\n","    address = str(address).lower()\n","    replacements = {\n","        \"street\": \"st\", \"road\": \"rd\", \"avenue\": \"ave\", \"drive\": \"dr\",\n","        \"lane\": \"ln\", \"court\": \"ct\", \"north\": \"n\", \"south\": \"s\",\n","        \"east\": \"e\", \"west\": \"w\"\n","    }\n","    for k, v in replacements.items():\n","        address = address.replace(k, v)\n","    address = address.replace(\",\", \"\").strip()\n","    return address\n","\n","US_STATE_ABBR = {\n","    'alabama': 'al', 'alaska': 'ak', 'arizona': 'az', 'arkansas': 'ar', 'california': 'ca', 'colorado': 'co',\n","    'connecticut': 'ct', 'delaware': 'de', 'florida': 'fl', 'georgia': 'ga', 'hawaii': 'hi', 'idaho': 'id',\n","    'illinois': 'il', 'indiana': 'in', 'iowa': 'ia', 'kansas': 'ks', 'kentucky': 'ky', 'louisiana': 'la',\n","    'maine': 'me', 'maryland': 'md', 'massachusetts': 'ma', 'michigan': 'mi', 'minnesota': 'mn',\n","    'mississippi': 'ms', 'missouri': 'mo', 'montana': 'mt', 'nebraska': 'ne', 'nevada': 'nv',\n","    'new hampshire': 'nh', 'new jersey': 'nj', 'new mexico': 'nm', 'new york': 'ny', 'north carolina': 'nc',\n","    'north dakota': 'nd', 'ohio': 'oh', 'oklahoma': 'ok', 'oregon': 'or', 'pennsylvania': 'pa',\n","    'rhode island': 'ri', 'south carolina': 'sc', 'south dakota': 'sd', 'tennessee': 'tn', 'texas': 'tx',\n","    'utah': 'ut', 'vermont': 'vt', 'virginia': 'va', 'washington': 'wa', 'west virginia': 'wv',\n","    'wisconsin': 'wi', 'wyoming': 'wy'\n","}\n","\n","def normalize_state(state):\n","    state = state.strip().lower()\n","    return US_STATE_ABBR.get(state, state)\n","\n","def extract_city_state_zip(formatted_address):\n","    try:\n","        parts = formatted_address.lower().split(',')\n","        city = parts[-3].strip() if len(parts) >= 3 else ''\n","        state_zip = parts[-2].strip().split()\n","        state = state_zip[0] if len(state_zip) >= 1 else ''\n","        zip_code = state_zip[1] if len(state_zip) >= 2 else ''\n","        return city, state, zip_code\n","    except:\n","        return '', '', ''\n","\n","def broad_name_match(name1, name2, threshold=CONFIG['matching_threshold']):\n","    name1 = str(name1).lower().strip() if pd.notna(name1) else ''\n","    name2 = str(name2).lower().strip() if pd.notna(name2) else ''\n","    return SequenceMatcher(None, name1, name2).ratio() >= threshold\n","\n","def cuisine_match(primary_type):\n","    primary_type = primary_type.lower() if isinstance(primary_type, str) else ''\n","    return 1 if any(cuisine in primary_type for cuisine in CONFIG['target_cuisines']) else 0\n","\n","def call_places_api(textQuery):\n","    response = requests.post(\n","        \"https://places.googleapis.com/v1/places:searchText\",\n","        json={\"textQuery\": textQuery},\n","        headers={\n","            \"Content-Type\": \"application/json\",\n","            \"X-Goog-Api-Key\": CONFIG['api_key'],\n","            \"X-Goog-FieldMask\": \"places.displayName,places.formattedAddress,places.primaryType,places.businessStatus,places.websiteUri\"\n","        }\n","    )\n","    return response.json().get('places', []) if response.status_code == 200 else []\n","\n","leads_df = pd.read_csv(CONFIG['input_file'], encoding='latin1')\n","leads_df[CONFIG['column_mapping']['restaurant_name']] = leads_df[CONFIG['column_mapping']['restaurant_name']].apply(clean_text)\n","leads_df[CONFIG['column_mapping']['postal_code']] = leads_df[CONFIG['column_mapping']['postal_code']].apply(normalize_postal_code)\n","\n","leads_df['full_address'] = leads_df[CONFIG['column_mapping']['address']].fillna('') + ', ' + \\\n","                           leads_df[CONFIG['column_mapping']['city']].fillna('') + ', ' + \\\n","                           leads_df[CONFIG['column_mapping']['state']].fillna('') + ' ' + \\\n","                           leads_df[CONFIG['column_mapping']['postal_code']].fillna('') + ', ' + \\\n","                           leads_df[CONFIG['column_mapping']['country']].fillna('')\n","leads_df['full_address'] = leads_df['full_address'].str.replace(', ,', ',', regex=False).str.strip(', ').str.lower()\n","\n","for col in ['google_display_name', 'google_formatted_address', 'google_primary_type', 'google_business_status', 'google_website_uri',\n","            'address_match', 'name_match', 'cuisine_match', 'status', 'website']:\n","    leads_df[col] = None if col.startswith('google_') else 0\n","\n","for index, row in leads_df.iterrows():\n","    has_street_address = pd.notna(row['address']) and row['address'].strip() != ''\n","\n","    if has_street_address:\n","        location_query = f\"{row['address']} {row['city']} {row['state']} {row['postal_code']} {row['country']}\"\n","        full_query = f\"{row['restaurant_name']} {location_query}\"\n","    else:\n","        location_query = f\"{row['restaurant_name']} {row['city']} {row['state']} {row['postal_code']}\"\n","        full_query = location_query\n","\n","    matched_place = None\n","    best_score = 0\n","    for place in call_places_api(full_query):\n","        display_name = place.get('displayName', {}).get('text', '')\n","        if not display_name:\n","            continue\n","\n","        lead_name = str(row['restaurant_name']).lower().strip() if pd.notna(row['restaurant_name']) else ''\n","        score = SequenceMatcher(None, lead_name, display_name.lower()).ratio()\n","\n","        if score > best_score:\n","            best_score = score\n","            matched_place = place\n","\n","    if not matched_place:\n","        continue\n","\n","    display_name = matched_place.get('displayName', {}).get('text', '')\n","    formatted_address = matched_place.get('formattedAddress', '')\n","    primary_type = matched_place.get('primaryType', '')\n","    business_status = matched_place.get('businessStatus', '')\n","    website_uri = matched_place.get('websiteUri', '')\n","\n","    leads_df.at[index, 'google_display_name'] = display_name\n","    leads_df.at[index, 'google_formatted_address'] = refine_address_with_unit(formatted_address)\n","    leads_df.at[index, 'google_primary_type'] = primary_type\n","    leads_df.at[index, 'google_business_status'] = business_status\n","    leads_df.at[index, 'google_website_uri'] = website_uri\n","\n","    if business_status and business_status != 'CLOSED_PERMANENTLY':\n","        leads_df.at[index, 'status'] = 1\n","\n","    # Name match: keyword match logic\n","    name_keywords = set(str(row['restaurant_name']).lower().split())\n","    display_keywords = set(display_name.lower().split())\n","    if name_keywords & display_keywords:\n","        leads_df.at[index, 'name_match'] = 1\n","\n","    leads_df.at[index, 'cuisine_match'] = cuisine_match(primary_type)\n","    if website_uri:\n","        leads_df.at[index, 'website'] = 1\n","\n","    if has_street_address:\n","        lead_addr = normalize_address(row['full_address'])\n","        google_addr = normalize_address(refine_address_with_unit(formatted_address))\n","        leads_df.at[index, 'address_match'] = 1 if fuzz.token_set_ratio(lead_addr, google_addr) >= 80 else 0\n","    else:\n","        google_city, google_state, google_zip = extract_city_state_zip(formatted_address)\n","        lead_state_abbr = normalize_state(row['state'])\n","        google_state_abbr = normalize_state(google_state)\n","\n","        zip_prefix_match = row['postal_code'][:3] == google_zip[:3]\n","        state_match = lead_state_abbr == google_state_abbr\n","\n","        if state_match and zip_prefix_match:\n","            leads_df.at[index, 'address_match'] = 1\n","\n","leads_df['lead_score'] = (\n","    leads_df['status'] * CONFIG['weights']['status'] +\n","    leads_df['cuisine_match'] * CONFIG['weights']['cuisine_match'] +\n","    leads_df['address_match'] * CONFIG['weights']['address_match'] +\n","    leads_df['name_match'] * CONFIG['weights']['name_match'] +\n","    leads_df['website'] * CONFIG['weights']['website']\n",") * 100\n","\n","leads_df.to_csv(CONFIG['output_file'], index=False)\n","print(f\"âœ… Process complete! Results saved to: {CONFIG['output_file']}\")\n"]}]}
